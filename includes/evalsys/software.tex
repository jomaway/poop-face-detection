\subsection{Software Komponenten} \
\label{subsec:evalsys_software}

Die Software beinhaltet mehrere Teilbereiche von dem Erkennen eines Triggers bis zur Ablage des vollständigen Videos. Durch recherche über Wildbewegungskameras konnten einige Bereiche der Videoaufnahme erleichtert werden \cite{rasp_ansteuerung}.

\subsubsection{Videoaufnahme}

Für die Ansteuerung der Raspberry Pi Kamera gibt es bereits eine Bibliothek die folgendermaßen eingebunden werden kann:

\begin{lstlisting}[language=Python]
from picamera import PiCamera
from picamera import PiCameraCircularIO
\end{lstlisting}

Somit kann die Kamera erkannt werden und Einstellungen vorgenommen werden.

\begin{lstlisting}[language=Python]
with PiCamera() as camera:
	camera.framerate = 25
	stream = PiCameraCircularIO(camera, seconds=(conf.get_secs_before() + conf.get_secs_after()))
	camera.start_recording(stream, format='h264')
	try:
		while True:
			camera.wait_recording(1)	
		finally:
			camera.stop_recording()
\end{lstlisting}

Im obigen Code wird die Bilderanzahl pro Sekunde eingestellt. Danach wird ein Ringpuffer initialisiert, der die Puffergröße von den Sekunden vor und nach einem Trigger hat. Damit sind die Grundeinstellungen durchgeführt und die Kamera kann mit dem Befehl \glqq{} camera.start\_recording \grqq{} aufnehmen. Dem Aufnahmestart wird dabei der Ringpuffer, sowie ein unterstütztes Videoformat übergeben.

Danach werden Triggersuche sowie Videoverarbeitung im Zyklus von einer Sekunde der durchlaufen. Die Wartezeit wird mittels der Aufnahme- und Warten-Funktion der Kamera realisiert. Am Ende des Programmes muss die Kameraaufnahme mit dem Befehl "`camera.stop\_recording"' beendet werden.

\subsubsection{Triggererkennung}
\label{subsubsec:triggererkennung}

Durch das Empfangen und Verifizieren des Bluetooth-Signals wird eine Triggerdatei mit der Endung ".trg" im Ordner recording/trigger erzeugt. Dies ist genauer in \ref{sec:com} beschrieben.

Der Name der Datei wird folgendermaßen dargestellt:
\begin{center}
	jahr\_monat\_tag-stunde\_minute\_sekunde.trg
\end{center}

Mit folgender Codezeile wird nach Triggerdateien im oben genannten Verzeichnis gesucht:

\begin{lstlisting}[language=Python]
triggerfiles = [f for f in os.listdir(conf.get_trigger_path()) if f.endswith(conf.get_trigger_fileextension())]
\end{lstlisting}

Der Systembefehl "`os.listdir"' listet alle Dateien eines Ordners auf. Der Pfad wird in den runden Klammern danach angegeben. In diesem Fall wird der Verzeichnispfad über eine get-Methode der Konfigurationsdatei ausgelesen, welcher auf den Ordner recording/trigger verweist. Um eine Triggerdatei zu finden werden nur die Dateien mit der Endung "`.trg"' aufgelistet. Dies wird mit der "`if"' (wenn)-Bedingung nach dem Systembefehl ausgeführt. Die Dateiendung wird ebenfalls über die Konfigurationsdatei (conf) bezogen.

Sobald Triggerdateien erkannt wurden, werden diese bearbeitet. Über die Benennung wird der Triggerzeitpunkt ermittelt. Falls die Triggerzeit größer als die aktuelle Zeit sein sollte, wird als Zeitpunkt die aktuelle Zeit verwendet.

\subsubsection{Videoverarbeitung}

Da bereits ein Trigger erkannt wurde und der Zeitpunkt des Auslösens bekannt ist, kann mit der Videoverarbeitung begonnen werden.

\begin{lstlisting}[language=Python]
beforetime = (currenttime - triggertime).total_seconds() + conf.get_secs_before()
\end{lstlisting}

Die Länge des Videos ist über eine für den Nutzer erstellte Konfigurationsdatei einstellbar gemacht. Dafür wird die Zeit in Sekunden ermittelt, die für den Videoabschnitt vor dem Triggersignal benötigt wird. Danach wird dieser Teil als Abschnitt A im Videoformat "`h264"' abgespeichert.

Hiermit ist das bisherige Videomaterial vor dem Trigger gesammelt und die Triggerdatei kann gelöscht werden. Das funktioniert mittels eines Systembefehls "`os.remove"'. Nun nimmt die Kamera die Sekunden nach dem Triggerzeitpunkt auf. Diese Aufnahme wird in "`h264"'-Format als Teil B gespeichert.

Da das "`h264"'-Format für die Anzeige auf einer Webapplikation nicht geeignet ist, muss diese in ein anderes Format umgewandelt werden. Dies passiert über ein weiteres Python-Programm, welches über einen Systembefehl angesteuert wird.

Mittels eines Systembefehle und dem Programm "`MP4Box"' können die Videoabschnitte konvertiert, zusammengefügt und in das Zielverzeichnis der Webapplikation verschoben werden \cite{convert_video}. Zuletzt werden die zwei nicht mehr benötigten Teilabschnitte gelöscht.

\subsubsection{Konfigurationsdatei}

Für das Python-Programm wurden zwei Konfigurationsdateien erstellt. Eine für den Benutzer zugängliche und festgelegte.
Die Nutzerkonfiguration besteht aus dem Zeitwert der Videoaufnahme vor dem Triggersignal in Sekunden und dem danach.
Die festgelegte Konfigurationsdatei beinhaltet Pfadnamen sowie Endungen von Trigger-, Video- und Loggerverzeichnissen und -dateien.

Das Auslesen der Informationen erfolgt über "`configurator.py"'. Dieser liest die einzelnen Elemente der Textdatei aus und kann diese mittels definierter get-Funktionen als Rückgabewert an ein anderes Programm übergeben.

Um dieses Python-Programm verwenden zu können muss der Konfigurationsparser wie folgt eingebunden werden:

\begin{lstlisting}[language=Python]
from poopfacedetection import configurator
conf = configurator.Configurator()
\end{lstlisting}


\subsubsection{Webserver}
Um die aufgenommenen videos leicht zugänglich zu machen, wurde ein einfacher Webserver in das System integriert. Basierend auf dem Python Framework Flask wurde dieser implementiert. Flask bietet eine gute Dokumentation und ist einfach Einzurichten, was es perfekt für Prototyping und kleine Projekte macht. Bei großen Webseiten und Projekten ist er vorallem aus performence Gründen ungeignet. Mehr Informationen und Dokumentationen zu Flask sind unter \href{http://flask.pocoo.org/}{flask.pocoo.org} zu finden. \\
\\
Der Webserver liegt im Verzeichnis /webapp und kann dort über das script run.sh gestartet werden. Es ist dann unter der IP-Adresse des Raspberry Pi erreichbar und beinhaltet drei Seiten welche in den nächsten Absätzen erleutert werden. 

\paragraph{Startseite} auf der die letzten Videos angezeigt werden.

\paragraph{Videoseite} auf der alle Videos angezeigt werden. Diese ist über einen link auf der Startseite oder über die Route /videos erreichbar.

\paragraph{Detailseite} auf der ein einzelnes Video angezeigt wird. Zusätzlich wird dort ein Verhaltensformular, siehe dazu auch Kapitel \ref{sec:verhaltensformular}, dargestellt. \\
\\
Die Webseite ist so aufgebaut, dass die aufgenommen Videos nach dem Verarbeiten nur in den Ordner webapp/static/videos kopiert werden müssen. Auf eine optische gestalltung und weitere Möglichkeiten der Konfiguration des Evaluation Systems über den Webserver wurde bewusst verzichtet, da der Fokus dieser Arbeit auf die anderen Teile gelegt wurde.

