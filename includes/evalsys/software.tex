\subsection{Software Komponenten} \
\label{subsec:evalsys_software}

Die Software beinhaltet mehrere Teilbereiche von dem Erkennen eines Triggers bis zur Ablage des vollständigen Videos. Die Software wurde in Python realisiert. Python ist durch sein weites Anwendungsspektrum gut für Prototyping geeignet. Die vielen Bibliotheken erleichtern das implementieren von Lösungen. Durch Recherche über Wildbewegungskameras konnten einige Bereiche der Videoaufnahme erleichtert werden \cite{rasp_ansteuerung}.

\subsubsection{Videoaufnahme}

Für die Ansteuerung der Raspberry Pi Kamera gibt es bereits eine Bibliothek namens picamera die folgendermaßen eingebunden werden kann:

\begin{lstlisting}[language=Python]
from picamera import PiCamera
from picamera import PiCameraCircularIO
\end{lstlisting}

Somit kann die Kamera erkannt werden und Einstellungen vorgenommen werden.

\begin{lstlisting}[language=Python]
with PiCamera() as camera:
	camera.framerate = 25
	stream = PiCameraCircularIO(camera, seconds=(conf.get_secs_before() + conf.get_secs_after()))
	camera.start_recording(stream, format='h264')
	try:
		while True:
			camera.wait_recording(1)	
		finally:
			camera.stop_recording()
\end{lstlisting}

Im obigen Code wird die Bilderanzahl pro Sekunde eingestellt. Danach wird ein Ringpuffer initialisiert, der die Puffergröße von den Sekunden vor und nach einem Trigger hat. Diese sind in einer Konfigurationsdatei hinterlegt (siehe Abschnitt \ref{subsubsec:configfile} ). Damit sind die Grundeinstellungen durchgeführt und die Kamera kann mit dem Befehl \glqq{} camera.start\_recording \grqq{} aufnehmen. Dem Aufnahmestart wird dabei der Ringpuffer, sowie ein unterstütztes Videoformat übergeben.

Danach werden Triggersuche sowie Videoverarbeitung im Zyklus von einer Sekunde der durchlaufen. Die Wartezeit wird mittels der Aufnahme- und Warten-Funktion der Kamera realisiert. Am Ende des Programmes muss die Kameraaufnahme mit dem Befehl "`camera.stop\_recording"' beendet werden.

\subsubsection{Triggererkennung}
\label{subsubsec:triggererkennung}

Durch das Empfangen und Verifizieren des Bluetooth-Signals wird eine Triggerdatei mit der Endung \glqq{}.trg\grqq{} im Ordner recording/trigger erzeugt. Dies ist genauer in Kapitel \ref{sec:com} beschrieben.

Der Name der Datei wird folgendermaßen dargestellt:
\begin{center}
	jahr\_monat\_tag-stunde\_minute\_sekunde.trg
\end{center}

Mit folgender Codezeile wird nach Triggerdateien im oben genannten Verzeichnis gesucht:

\begin{lstlisting}[language=Python]
triggerfiles = [f for f in os.listdir(conf.get_trigger_path()) if f.endswith(conf.get_trigger_fileextension())]
\end{lstlisting}

Der Systembefehl "`os.listdir"' listet alle Dateien eines Ordners auf. Der Pfad wird in den runden Klammern danach angegeben. In diesem Fall wird der Verzeichnispfad über eine get-Methode der Konfigurationsdatei ausgelesen, welcher auf den Ordner recording/trigger verweist. Um eine Triggerdatei zu finden werden nur die Dateien mit der Endung "`.trg"' aufgelistet. Dies wird mit der "`if"' (wenn)-Bedingung nach dem Systembefehl ausgeführt. Die Dateiendung wird ebenfalls über die Konfigurationsdatei (conf) bezogen.

Sobald Triggerdateien erkannt wurden, werden diese bearbeitet. Über die Benennung wird der Triggerzeitpunkt ermittelt. Falls die Triggerzeit größer als die aktuelle Zeit sein sollte, wird als Zeitpunkt die aktuelle Zeit verwendet.

\subsubsection{Videoverarbeitung}

Da bereits ein Trigger erkannt wurde und der Zeitpunkt des Auslösens bekannt ist, kann mit der Videoverarbeitung begonnen werden.

\begin{lstlisting}[language=Python]
beforetime = (currenttime - triggertime).total_seconds() + conf.get_secs_before()
\end{lstlisting}

Die Länge des Videos ist über eine für den Nutzer erstellte Konfigurationsdatei einstellbar gemacht. Dafür wird die Zeit in Sekunden ermittelt, die für den Videoabschnitt vor dem Triggersignal benötigt wird. Danach wird dieser Teil als Abschnitt A im Videoformat "`h264"' abgespeichert.

Hiermit ist das bisherige Videomaterial vor dem Trigger gesammelt und die Triggerdatei kann gelöscht werden. Das funktioniert mittels eines Systembefehls "`os.remove"'. Nun nimmt die Kamera die Sekunden nach dem Triggerzeitpunkt auf. Diese Aufnahme wird in "`h264"'-Format als Teil B gespeichert.

Da das "`h264"'-Format für die Anzeige auf einer Webapplikation nicht geeignet ist, muss diese in ein anderes Format umgewandelt werden. Dies passiert über ein weiteres Python-Programm, welches über einen Systembefehl angesteuert wird.

Mittels eines Systembefehle und dem Programm "`MP4Box"' \footnote{Mehr Informationen zum Programm Mp4Box sind \href{https://www.videohelp.com/software/My-MP4Box-GUI}{hier} zu finden.} können die Videoabschnitte konvertiert, zusammengefügt und in das Zielverzeichnis der Webapplikation verschoben werden. Zuletzt werden die zwei nicht mehr benötigten Teilabschnitte gelöscht.

\subsubsection{Konfigurationsdatei}
\label{subsubsec:configfile}

Für die Python-Programme wurden zwei Konfigurationsdateien erstellt. Eine für den Benutzer zugängliche und festgelegte.
Die Nutzerkonfiguration besteht aus dem Zeitwert der Videoaufnahme vor dem Triggersignal in Sekunden und dem danach.
Die festgelegte Konfigurationsdatei beinhaltet Pfadnamen sowie Endungen von Trigger-, Video- und Loggerverzeichnissen und -dateien.

Das Auslesen der Informationen erfolgt über "`configurator.py"'. Dieser liest die einzelnen Elemente der Textdatei aus und kann diese mittels definierter get-Funktionen als Rückgabewert an ein anderes Programm übergeben.

Um dieses Python-Programm verwenden zu können muss der Konfigurationsparser wie folgt eingebunden werden:

\begin{lstlisting}[language=Python]
from poopfacedetection import configurator
conf = configurator.Configurator()
\end{lstlisting}

Damit Python den configurator findet, muss dieser in das Verzeichnis /usr/lib/python3/dist-packages/poopfacedetection/ verschoben werden.

\subsubsection{Webserver}
Um die aufgenommenen videos leicht zugänglich zu machen, wurde ein einfacher Webserver in das System integriert. Basierend auf dem Python Framework Flask wurde dieser implementiert. Flask bietet eine gute Dokumentation und ist einfach einzurichten, was es perfekt für Prototyping und kleine Projekte macht. Bei großen Webseiten und Projekten ist er vorallem aus Performencegründen ungeignet. Mehr Informationen und Dokumentationen zu Flask sind unter \href{http://flask.pocoo.org/}{flask.pocoo.org} zu finden. \\
\\
Der Webserver liegt im Verzeichnis /webapp und kann dort über das script run.sh gestartet werden. Er ist dann unter der IP-Adresse des Raspberry Pi erreichbar und beinhaltet drei Seiten, welche in den nächsten Absätzen erleutert werden. 

\paragraph{Die Startseite} zeigt eine kurze Übersicht und verlinkt auf die Videoseite.

\paragraph{Die Videoseite} zeigt alle Videos an. Diese Seite ist über einen Link auf der Startseite oder über die Route /videos erreichbar.

\paragraph{Die Detailseite} zeigt ein einzelnes Video an. Zusätzlich wird dort ein Verhaltensformular, siehe dazu auch Kapitel \ref{sec:verhaltensformular}, dargestellt. \\
\\
Die Webseite ist so aufgebaut, dass die aufgenommenen Videos nach dem Verarbeiten nur in den Ordner webapp/static/videos kopiert werden müssen. Auf eine optische Gestalltung und weitere Möglichkeiten der Konfiguration des Evaluation-Systems über den Webserver wurde bewusst verzichtet, da der Fokus dieser Arbeit auf die anderen Teile gelegt wurde.

\subsubsection{Aktuelle Probleme}
\label{subsubsec:software_problems}

Da während der Lösungsfindung Probleme aufgetaucht sind, wird im Folgenden auf diese eingegangen und eine Möglichkeit zur Vermeidung beschrieben.

\paragraph{Ausführung als superuser:} Um die Programme ausführen zu können, sind Systemrechte erforderlich. Da bei der Ansteuerung der Kamera und des BLE Chips auf Systemfunktionen zugegriffen wird. Eine alternative Lösung dafür ist die Vergabe von den entsprechenden Rechten an den aktuellen Anwender.

\paragraph{Ausführung im richtigen Verzeichnis:} Damit die Programme funktionieren, müssen sie aus dem entsprechenden Verzeichnis aufgerufen werden, da Links sonst fehlinterpretiert werden können. Um dieses Problem zu lösen, wurden absolute Pfadangaben in der Konfigurationsdatei hinterlegt. Eine Lösung die auf relativen Pfaden basiert, wäre für die Portabilität des Projektes nützlicher.

\paragraph{Abspielen der Videos:} Zum Abspielen der Videos muss von einem anderen Rechner auf die Webseite zugegriffen werden, da mit dem vorinstallierten Browser des Raspberry Pi's das Abspielen der Videos nicht problemlos funktioniert. 

\subsubsection{Benutzung}
\label{subsubsec:using}

Um die Benutzbarkeit des Systems zu vereinfachen, wurde ein Shell-Skript run.sh erstellt, welches sich um die Ausführung der benötigten Python-Programme kümmert. Dieses liegt im Verzeichnis home/pi/poop-face-detection/eval-sys/. Dort wurde auch eine README-Datei mit weiteren Information zur Benutzung hinterlegt.

Ist die IP-Adresse des Raspberry Pi bekannt, ist auch eine Verbindung über SSH möglich.
